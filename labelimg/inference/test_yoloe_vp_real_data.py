#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import os
import numpy as np
import glob

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from yoloe_vp import YOLOEWrapper
    print("âœ“ æˆåŠŸå¯¼å…¥ YOLOEWrapper")
except ImportError as e:
    print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def load_classes(classes_path):
    """åŠ è½½ç±»åˆ«åç§°"""
    with open(classes_path, 'r', encoding='utf-8') as f:
        classes = [line.strip() for line in f.readlines() if line.strip()]
    return classes

def parse_yolo_annotation(txt_path, img_width=640, img_height=480):
    """è§£æYOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
    
    Args:
        txt_path: æ ‡æ³¨æ–‡ä»¶è·¯å¾„
        img_width: å›¾åƒå®½åº¦
        img_height: å›¾åƒé«˜åº¦
    
    Returns:
        bboxes: [[x1, y1, x2, y2], ...] æ ¼å¼çš„è¾¹ç•Œæ¡†
        class_ids: [class_id, ...] æ ¼å¼çš„ç±»åˆ«ID
    """
    bboxes = []
    class_ids = []
    
    if not os.path.exists(txt_path):
        return np.array([]), np.array([])
    
    with open(txt_path, 'r') as f:
        lines = f.readlines()
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        parts = line.split()
        if len(parts) != 5:
            continue
        
        class_id = int(parts[0])
        center_x = float(parts[1])
        center_y = float(parts[2])
        width = float(parts[3])
        height = float(parts[4])
        
        # è½¬æ¢ä¸ºç»å¯¹åæ ‡
        x1 = (center_x - width/2) * img_width
        y1 = (center_y - height/2) * img_height
        x2 = (center_x + width/2) * img_width
        y2 = (center_y + height/2) * img_height
        
        bboxes.append([x1, y1, x2, y2])
        class_ids.append(class_id)
    
    return np.array(bboxes), np.array(class_ids)

def test_with_real_data():
    """ä½¿ç”¨set16_testçš„çœŸå®æ•°æ®æµ‹è¯•ç±»åˆ«ç®¡ç†"""
    print("\n=== ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•ç±»åˆ«ç®¡ç†ç¨³å®šæ€§ ===")
    
    # æ•°æ®è·¯å¾„
    data_dir = "/Users/patrick/Desktop/labeling/Bunnpris-data/set16_test"
    classes_path = os.path.join(data_dir, "classes.txt")
    
    # åŠ è½½ç±»åˆ«åç§°
    class_names = load_classes(classes_path)
    print(f"åŠ è½½ç±»åˆ«: {class_names}")
    print(f"æ€»ç±»åˆ«æ•°: {len(class_names)}")
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = sorted(glob.glob(os.path.join(data_dir, "*.jpg")))
    print(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    # åˆå§‹åŒ–wrapper
    wrapper = YOLOEWrapper()
    print(f"åˆå§‹çŠ¶æ€ - ç±»åˆ«æ•°é‡: {wrapper.num_classes}, ç±»åˆ«æ˜ å°„: {wrapper.class_mapping}")
    
    # é€‰æ‹©å‰å‡ ä¸ªæ–‡ä»¶ä½œä¸ºåˆå§‹prompt
    initial_prompt_count = 3
    prompt_images = image_files[:initial_prompt_count]
    
    print(f"\n--- ä½¿ç”¨å‰{initial_prompt_count}ä¸ªå›¾åƒä½œä¸ºåˆå§‹prompt ---")
    
    # æ”¶é›†åˆå§‹promptsçš„æ•°æ®
    initial_bboxes = []
    initial_cls = []
    valid_prompts = []
    
    for img_path in prompt_images:
        # è·å–å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
        txt_path = img_path.replace('.jpg', '.txt')
        bboxes, cls_ids = parse_yolo_annotation(txt_path)
        
        if len(bboxes) > 0 and len(cls_ids) > 0:
            initial_bboxes.append(bboxes)
            initial_cls.append(cls_ids)
            valid_prompts.append(img_path)
            print(f"  {os.path.basename(img_path)}: {len(cls_ids)} ä¸ªå¯¹è±¡, ç±»åˆ«: {cls_ids}")
    
    if not valid_prompts:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆå§‹promptæ•°æ®")
        return None
    
    # ä½¿ç”¨auto_label_with_vpè¿›è¡Œåˆå§‹åŒ–
    print("\n--- åˆå§‹åŒ–VPE ---")
    visuals = {
        'bboxes': initial_bboxes,
        'cls': initial_cls
    }
    
    # é€‰æ‹©ä¸€ä¸ªç›®æ ‡å›¾åƒè¿›è¡Œæµ‹è¯•
    target_image = image_files[initial_prompt_count] if len(image_files) > initial_prompt_count else image_files[-1]
    
    try:
        predictions = wrapper.auto_label_with_vp(
            prompt_image_paths=valid_prompts,
            visuals=visuals,
            target_image_path=target_image,
            conf_thresh=0.3
        )
        
        print(f"\n--- åˆå§‹åŒ–ç»“æœ ---")
        print(f"ç±»åˆ«æ•°é‡: {wrapper.num_classes}")
        print(f"ç±»åˆ«æ˜ å°„: {wrapper.class_mapping}")
        print(f"å¯¹è±¡é›†åˆ: {wrapper.initial_object_set}")
        print(f"é¢„æµ‹ç»“æœæ•°é‡: {len(predictions)}")
        
        # éªŒè¯ç±»åˆ«ä¸€è‡´æ€§
        consistency_check = wrapper._validate_class_consistency()
        print(f"ç±»åˆ«ä¸€è‡´æ€§æ£€æŸ¥: {'âœ“ é€šè¿‡' if consistency_check else 'âœ— å¤±è´¥'}")
        
        # éªŒè¯VPEå¼ é‡å½¢çŠ¶
        if wrapper.final_refined_embeddings_tensor is not None:
            expected_shape = (1, wrapper.num_classes, wrapper.embedding_dim)
            actual_shape = wrapper.final_refined_embeddings_tensor.shape
            shape_correct = actual_shape == expected_shape
            print(f"VPEå¼ é‡å½¢çŠ¶: {actual_shape}, æœŸæœ›: {expected_shape}, {'âœ“ æ­£ç¡®' if shape_correct else 'âœ— é”™è¯¯'}")
        else:
            print("VPEå¼ é‡ä¸ºNone")
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    return wrapper

def test_incremental_updates(wrapper, data_dir):
    """æµ‹è¯•å¢é‡æ›´æ–°"""
    print("\n=== æµ‹è¯•å¢é‡æ›´æ–° ===")
    
    if wrapper is None:
        print("âŒ wrapperä¸ºNoneï¼Œè·³è¿‡å¢é‡æ›´æ–°æµ‹è¯•")
        return
    
    # è·å–æ›´å¤šå›¾åƒè¿›è¡Œå¢é‡æµ‹è¯•
    image_files = sorted(glob.glob(os.path.join(data_dir, "*.jpg")))
    
    # é€‰æ‹©å‡ ä¸ªæ–°çš„å›¾åƒè¿›è¡Œå¢é‡æ›´æ–°æµ‹è¯•
    test_images = image_files[5:8] if len(image_files) > 8 else image_files[-3:]
    
    for i, test_img in enumerate(test_images):
        print(f"\n--- å¢é‡æµ‹è¯• {i+1}: {os.path.basename(test_img)} ---")
        
        try:
            predictions = wrapper.auto_label_with_vp(
                prompt_image_paths=[],  # ç©ºçš„åˆå§‹promptsï¼Œä½¿ç”¨å·²æœ‰çš„VPE
                visuals={'bboxes': [], 'cls': []},
                target_image_path=test_img,
                conf_thresh=0.3
            )
            
            print(f"é¢„æµ‹ç»“æœæ•°é‡: {len(predictions)}")
            print(f"å½“å‰ç±»åˆ«æ•°é‡: {wrapper.num_classes}")
            print(f"å½“å‰ç±»åˆ«æ˜ å°„: {wrapper.class_mapping}")
            
            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            for j, pred in enumerate(predictions):
                print(f"  é¢„æµ‹ {j+1}: ç±»åˆ«ID={pred['class_id']}, åç§°='{pred['class_name']}', ç½®ä¿¡åº¦={pred['confidence']:.3f}")
            
            # éªŒè¯ç±»åˆ«ä¸€è‡´æ€§
            consistency_check = wrapper._validate_class_consistency()
            print(f"ç±»åˆ«ä¸€è‡´æ€§æ£€æŸ¥: {'âœ“ é€šè¿‡' if consistency_check else 'âœ— å¤±è´¥'}")
            
        except Exception as e:
            print(f"âŒ å¢é‡æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        # æµ‹è¯•çœŸå®æ•°æ®
        wrapper = test_with_real_data()
        
        if wrapper:
            # æµ‹è¯•å¢é‡æ›´æ–°
            data_dir = "/Users/patrick/Desktop/labeling/Bunnpris-data/set16_test"
            test_incremental_updates(wrapper, data_dir)
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 